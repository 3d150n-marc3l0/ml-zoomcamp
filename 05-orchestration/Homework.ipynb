{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36e93fe-1372-4af2-bbce-f33ea471eadd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ed7b1ca-8ba1-4afe-9d1d-d54a08a0a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12e9ae-15fb-414a-824a-01e43aa4d710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4d9b84-fcaf-4eb9-947b-35e9bf0c97a4",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c7d8d-53d6-457e-8c2b-a5292f9d455b",
   "metadata": {},
   "source": [
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly. \n",
    "> That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "> Note: we recommend using python 3.11 in this homework.\n",
    "\n",
    "In this homework, we will use the Bank Marketing dataset. Download it from [here](https://archive.ics.uci.edu/static/public/222/bank+marketing.zip).\n",
    "\n",
    "You can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n",
    "unzip bank+marketing.zip \n",
    "unzip bank.zip\n",
    "```\n",
    "\n",
    "We need `bank-full.csv`.\n",
    "\n",
    "You can also access the copy of `back-full.csv` directly:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/bank-full.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496319f-9570-4ce3-a733-531dfafa4273",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647c790a-11d9-40b9-af50-f585086d6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpipenv\u001b[0m, version 2024.1.0\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871691c-61c9-4253-aa30-1cafa309f9eb",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.5.2\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework\n",
    "and do it there. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a031392-bf6e-40fd-8ddf-507e4973f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974189d3-3487-41aa-94b3-e09cfbe80f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of scikit-learn: sha256:03b6158efa3faaf1feea3faa884c840ebd61b6484167c711548fce208ea09445\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo Pipfile.lock\n",
    "with open('../../Pipfile.lock') as f:\n",
    "    lock_data = json.load(f)\n",
    "\n",
    "# Cambia 'nombre_de_la_biblioteca' por el nombre de la biblioteca que buscas\n",
    "lib_name = 'scikit-learn'\n",
    "\n",
    "# Extraer el hash\n",
    "lib_hashes = lock_data['default'].get(lib_name, {}).get('hashes', [])\n",
    "\n",
    "print(f\"Hash of {lib_name}: {lib_hashes[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093a3c77-907f-43ff-88e2-2a1d0ac9a9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sha256:03b6158efa3faaf1feea3faa884c840ebd61b6484167c711548fce208ea09445'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"sha256:03b6158efa3faaf1feea3faa884c840ebd61b6484167c711548fce208ea09445\"\n",
    "lib_hashes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d76c9-8419-4abd-97e4-b80761537fec",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job', 'duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2024/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2024/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2024/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23c06bd6-3f2a-4712-be88-253704f18b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40K\n",
      "-rw-rw-r-- 1 aztleclan aztleclan  645 oct 25 12:51 app.py\n",
      "-rw-rw-r-- 1 aztleclan aztleclan  560 oct 25 12:44 dv.bin\n",
      "drwxrwxr-x 2 aztleclan aztleclan 4,0K oct 25 11:54 homework\n",
      "-rw-rw-r-- 1 aztleclan aztleclan  13K oct 25 12:52 Homework.ipynb\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 4,9K oct 25 11:53 homework.md\n",
      "-rw-rw-r-- 1 aztleclan aztleclan  850 oct 25 12:44 model1.bin\n",
      "-rw-rw-r-- 1 aztleclan aztleclan    0 oct 25 12:42 run_app.sh\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828302e-eadf-4bb5-8d4f-ffe64beba90b",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d09a38-d962-484e-a0e6-7ced1d6f612b",
   "metadata": {},
   "source": [
    "\n",
    "What's the probability that this client will get a subscription? \n",
    "\n",
    "* 0.359\n",
    "* 0.559\n",
    "* 0.759\n",
    "* 0.959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a194a136-a06f-42d2-9530-22814f0235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07ba0948-662a-44ac-8186-c7aa6e2ed824",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dv.bin', 'rb') as f:\n",
    "    dv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2680bfeb-88cd-4b4c-ad45-e05af4b48f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model1.bin', 'rb') as f:\n",
    "    model1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba78cdd1-9d54-438c-bd93-a1ac5e8507e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_input_data = dv.transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcfe1a79-1944-4544-8f0d-e8d488ff22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c095890-d806-4c3c-a355-d4242c7159e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model1.predict_proba(dv_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6f74731-4a62-462d-9d40-9bdb1a8f8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_proba[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "904fe059-eb21-4c1f-93d1-459695a360d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75909665])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba04f7-b1b2-4a57-86a4-5bc47cf4ae2c",
   "metadata": {},
   "source": [
    "What's the probability that this client will get a subscription? \n",
    "\n",
    "* 0.359\n",
    "* 0.559\n",
    "* **0.759** <strong style=\"font-size: 24px;\">&larr;</strong>\n",
    "* 0.959"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f3867-6dfa-45d1-9ef1-c3e944a2a994",
   "metadata": {},
   "source": [
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "3d8bb28974e55edefa000fe38fd3ed12  model1.bin\n",
    "7d37616e00aa80f2152b8b0511fc2dff  dv.bin\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b213e0f6-a7b9-40df-ad5f-371d9e154663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d8bb28974e55edefa000fe38fd3ed12  model1.bin\n",
      "7d37616e00aa80f2152b8b0511fc2dff  dv.bin\n"
     ]
    }
   ],
   "source": [
    "!md5sum model1.bin dv.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bc5c5-9c4a-43b5-bab5-ecf1c6b542e0",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"student\", \"duration\": 280, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3ee4c-ce9c-4975-b211-fefee4ceffb2",
   "metadata": {},
   "source": [
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "* 0.335\n",
    "* 0.535\n",
    "* 0.735\n",
    "* 0.935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cb2fed7-f737-4791-9908-77738ac485c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33480703475511053]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "client = {\"job\": \"student\", \"duration\": 280, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23baa39e-4787-48eb-873c-c33fae03d104",
   "metadata": {},
   "source": [
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "* **0.335** <strong style=\"font-size: 24px;\">&larr;</strong>\n",
    "* 0.535\n",
    "* 0.735\n",
    "* 0.935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d32c3-b049-42cf-a139-bc45d7c4b227",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.11.5-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.11.5-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.11.5-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.11.5-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53cf3e-518c-4176-9786-74ba064d94c1",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.11.5-slim`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f98e55-ff3a-44d1-a627-294ffad8f4e5",
   "metadata": {},
   "source": [
    "So what's the size of this base image?\n",
    "\n",
    "* 45 MB\n",
    "* 130 MB\n",
    "* 245 MB\n",
    "* 330 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd2787e6-680d-45c5-a170-6dd67c9fdcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                      TAG           IMAGE ID       CREATED         SIZE\n",
      "svizor/zoomcamp-model                           3.11.5-slim   975e7bdca086   6 days ago      130MB\n",
      "ollama/ollama                                   latest        1577d5e882da   4 weeks ago     3.27GB\n",
      "mlops-magic-platform                            latest        7d30dd20e974   4 months ago    4.52GB\n",
      "pgvector/pgvector                               0.6.0-pg16    a608718e732f   8 months ago    427MB\n",
      "apache/airflow                                  2.5.1         282394d57c1e   21 months ago   1.23GB\n",
      "redis                                           latest        19c51d4327cf   21 months ago   117MB\n",
      "postgres                                        13            beb2ef252f25   21 months ago   373MB\n",
      "docker.elastic.co/elasticsearch/elasticsearch   8.4.3         ce2b9dc7fe85   2 years ago     1.26GB\n",
      "elasticsearch                                   7.10.1        558380375f1a   3 years ago     774MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352de9d-ccf6-41a8-ab8e-b016b9b57b33",
   "metadata": {},
   "source": [
    "So what's the size of this base image?\n",
    "\n",
    "* 45 MB\n",
    "* **130 MB** <strong style=\"font-size: 24px;\">&larr;</strong>\n",
    "* 245 MB\n",
    "* 330 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc78fd5-af1a-406a-a31d-d096bfa227c0",
   "metadata": {},
   "source": [
    "# Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:3.11.5-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1e46-a72b-4870-afe3-43fca5aa8e42",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14f574-e89d-49bf-96b7-1128aa2cc946",
   "metadata": {},
   "source": [
    "\n",
    "What's the probability that this client will get a subscription now?\n",
    "\n",
    "* 0.287\n",
    "* 0.530\n",
    "* 0.757\n",
    "* 0.960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dd16f12-0547-422a-8a8c-a172a66d51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                      PORTS                                       NAMES\n",
      "6c9640589774   zoomcamp-hw05:3.10.12-slim                            \"pipenv run flask ru…\"   13 seconds ago   Up 12 seconds               0.0.0.0:5000->5000/tcp, :::5000->5000/tcp   awesome_euclid\n",
      "21b001723a42   ollama/ollama                                         \"/bin/ollama serve\"      12 hours ago     Exited (0) 11 hours ago                                                 ollama\n",
      "919a85b61f15   docker.elastic.co/elasticsearch/elasticsearch:8.4.3   \"/bin/tini -- /usr/l…\"   12 hours ago     Exited (143) 11 hours ago                                               elasticsearch\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "497ab54b-3196-4939-89b3-5c0605a7b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7590966516879658]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8712b67-eb1d-406c-ae6f-4f4561a9c75e",
   "metadata": {},
   "source": [
    "\n",
    "What's the probability that this client will get a subscription now?\n",
    "\n",
    "* 0.287\n",
    "* 0.530\n",
    "* **0.757** <strong style=\"font-size: 24px;\">&larr;</strong>\n",
    "* 0.960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd83b1-db11-4658-9d36-37ba54b59c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2024/homework/hw05\n",
    "* If your answer doesn't match options exactly, select the closest one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
